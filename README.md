# Hyperbolic embeddings of MEG brain networks using FHNN 

This project computes the hyperbolic embeddings of MEG brain networks using the Fully Hyperbolic Neural Network model. See references below:

*Weize Chen, Xu Han, Yankai Lin, Hexu Zhao, Zhiyuan Liu, Peng Li, Maosong Sun, and Jie Zhou. 2022. Fully Hyperbolic Neural Networks. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5672â€“5686, Dublin, Ireland. Association for Computational Linguistics.*

*Ramirez, H., Tabarelli, D., Brancaccio, A., Belardinelli, P., Marsh, E.B., Funke, M., Mosher, J.C., Maestu, F., Xu, M. and Pantazis, D., 2025. Fully hyperbolic neural networks: A novel approach to studying aging trajectories. IEEE Journal of Biomedical and Health Informatics.*


# Project organization for network embedding
Source code based on [HGCN](https://github.com/HazyResearch/hgcn) and [FHNN](https://github.com/chenweize1998/fully-hyperbolic-nn) repositories. File structure for FHNN source code:

```
ðŸ“¦gcn
 â”£ ðŸ“‚data
 â”£ ðŸ“‚layers
 â”ƒ â”£ ðŸ“œ__init__.py
 â”ƒ â”£ ðŸ“œatt_layers.py
 â”ƒ â”£ ðŸ“œhyp_layers.py    # Defines Lorentz Graph Convolutional Layer
 â”ƒ â”— ðŸ“œlayers.py
 â”£ ðŸ“‚manifolds
 â”ƒ â”£ ðŸ“œ__init__.py
 â”ƒ â”£ ðŸ“œbase.py
 â”ƒ â”£ ðŸ“œeuclidean.py
 â”ƒ â”£ ðŸ“œhyperboloid.py
 â”ƒ â”£ ðŸ“œlmath.py         # Math related to our manifold
 â”ƒ â”£ ðŸ“œlorentz.py       # Our manifold
 â”ƒ â”£ ðŸ“œpoincare.py
 â”ƒ â”— ðŸ“œutils.py
 â”£ ðŸ“‚models
 â”ƒ â”£ ðŸ“œ__init__.py
 â”ƒ â”£ ðŸ“œbase_models.py
 â”ƒ â”£ ðŸ“œdecoders.py      # Include FHNN decoder
 â”ƒ â”— ðŸ“œencoders.py      # Include FHNN encoder
 â”£ ðŸ“‚optim
 â”£ ðŸ“‚utils
 â”£ ðŸ“œstep1_import_plv_matrices.py       # Imports MEG PLV matrices from *.mat files
 â”£ ðŸ“œstep2_train_graph_iteration.py     # Computes hyperbolic embeddings
 â”£ ðŸ“œstep3_vci_visualization.py         # Visualizes hyperbolic embeddings
 
 ```

## Training FHNN model using Graph Iteration
Arguments passed to program:

`--task` Specifies task. Can be [lp], lp denotes link prediction.

`--act` Activation function (e.g. relu, tanh). Use None for no activation.

`--dataset` Specifies dataset.

`--lr` Specifies learning rate.

`--dim` Specifies dimension of embeddings.

`--num-layers` Specifies number of layers.

`--bias` To enable the bias, set it to 1.

`--dropout` Specifies dropout rate.

`--weight-decay` Specifies weight decay value.

`--log-freq` Interval for logging.

For other arguments, see `config.py`

In a Jupyter notebook, you can run: 

! python train_graph_iteration.py \
    --task lp \
    --act None \
    --dataset vci \
    --model HyboNet \
    --lr 0.05 \
    --dim 3 \
    --num-layers 2 \
    --bias 1 \
    --dropout 0.25 \
    --weight-decay 1e-3 \
    --manifold Lorentz \
    --log-freq 5 \
    --cuda -1 \
    --patience 50 \
    --grad-clip 0.1 \
    --seed 1234 \
    --save 1

In a terminal, run as follows: 

```bash
python step2_train_graph_iteration.py --task lp --act None --dataset vci --model HyboNet --lr 0.05 --dim 3 --num-layers 2 --bias 1 --dropout 0.25 --weight-decay 1e-3 --manifold Lorentz --log-freq 5 --cuda -1 --patience 50 --grad-clip 0.1 --seed 1234 --save 1
```

## Project installation

If you use conda, you can recreate the environment with:

```bash
conda env create -f environment.yml -n <env-name>
conda activate <env-name>
```
